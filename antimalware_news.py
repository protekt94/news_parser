from main import news_antimalware
import requests
from bs4 import BeautifulSoup
import json

import datetime
from pprint import pprint

def get_antimalware_news():
    r = requests.get(url=news_antimalware.url, headers=news_antimalware.headers)

    soup = BeautifulSoup(r.text, "lxml")
    articles_cards = soup.find_all("div", class_="view-content")
    antimalware_news = {}
    with open('news_dict.json') as file:
        data = json.load(file)
        data.update({"article_title": "1"})
        pprint(data)
        for article in articles_cards:
            for i_article in article.find_all("div", class_='node node-news node-teaser clearfix'):
                article_title = i_article.find("h2").text
                article_desc = i_article.find("p").text.strip()
                article_url = i_article.find("a").get("href")
                article_date = article_url.split('/')[2].split('-')[:3]
                article_date = ' '.join(article_date)
                article_date = str(datetime.datetime.strptime(article_date, '%Y %m %d').date())

                article_id = article_url.split('/')[3]
                article_url = 'https://www.anti-malware.ru/' + article_url

                antimalware_news[article_id] = {
                    "article_title": article_title,
                    "article_desc": article_desc,
                    "article_url": article_url,
                    "article_date": article_date
                }
    # with open("news_dict.json", "a+") as file:
    #     json.dump(data, file, ensure_ascii=False, indent=4)


def main():
    get_antimalware_news()


if __name__ == '__main__':
    main()
